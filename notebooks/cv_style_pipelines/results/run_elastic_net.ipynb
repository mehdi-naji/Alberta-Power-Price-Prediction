{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sktime.forecasting.compose import TransformedTargetForecaster\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sktime.forecasting.compose import make_reduction\n",
    "import requests\n",
    "from sktime.forecasting.model_selection import (\n",
    "    ExpandingWindowSplitter,\n",
    ")\n",
    "from sktime.transformations.series.boxcox import LogTransformer\n",
    "from lightgbm import LGBMRegressor\n",
    "from sktime.forecasting.model_evaluation import evaluate\n",
    "from sktime.performance_metrics.forecasting import MeanSquaredError\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima_process import arma_generate_sample\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "import statsmodels.api as sm\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from warnings import simplefilter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No log transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/train/X_train.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    "    index_col=\"date\",\n",
    ")\n",
    "\n",
    "y_train = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/train/y_train.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    "    index_col=\"date\",\n",
    ")\n",
    "\n",
    "X_train = X_train.sort_values(by=\"date\")\n",
    "X_train = X_train.asfreq(\"H\")\n",
    "y_train = y_train.sort_values(by=\"date\")\n",
    "y_train = y_train.asfreq(\"H\")\n",
    "\n",
    "cols_for_log_transform = list(set(X_train.columns) - set(list(X_train.columns[X_train.lt(3).any()])) - set([\"weekly_profile\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/test/X_test.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    "    index_col=\"date\",\n",
    ")\n",
    "\n",
    "y = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/test/y_test.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    "    index_col=\"date\",\n",
    ")\n",
    "\n",
    "X = X.sort_values(by=\"date\")\n",
    "X = X.asfreq(\"H\")\n",
    "y = y.sort_values(by=\"date\")\n",
    "y = y.asfreq(\"H\")\n",
    "\n",
    "X_test = X[:\"2023-03-31\"]\n",
    "y_test_full = y[:\"2023-03-31\"]\n",
    "forecast_len = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sktime.forecasting.compose import ForecastingPipeline\n",
    "from sktime.transformations.series.adapt import TabularToSeriesAdaptor\n",
    "from sktime.transformations.compose import ColumnwiseTransformer\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "\n",
    "def initialize_lgbm_forecaster():\n",
    "    pipe = ForecastingPipeline(\n",
    "        steps=[\n",
    "            (\"log_column_transformer\", ColumnwiseTransformer(LogTransformer(), columns=cols_for_log_transform)),\n",
    "            (\"std_column_transformer\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "            (\n",
    "                \"forecaster\",\n",
    "                TransformedTargetForecaster(\n",
    "                    [\n",
    "                        (\"log_column_transformer\", LogTransformer()),\n",
    "                        (\"std_column_transformer\", TabularToSeriesAdaptor(StandardScaler())),\n",
    "                        (\n",
    "                            \"forecast\",\n",
    "                            make_reduction(\n",
    "                                ElasticNetCV(cv=TimeSeriesSplit(n_splits=5), n_jobs=-1, random_state=42),  \n",
    "                                window_length=24,\n",
    "                                strategy=\"direct\",\n",
    "                            ),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return pipe\n",
    "\n",
    "lgbm_pipeline = initialize_lgbm_forecaster()\n",
    "\n",
    "fh = ForecastingHorizon(np.arange(1, 12 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_prediction_df = pd.DataFrame(index=y_test_full.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 {color: black;background-color: white;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 pre{padding: 0;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-toggleable {background-color: white;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-estimator:hover {background-color: #d4ebff;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-item {z-index: 1;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-parallel::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-parallel-item:only-child::after {width: 0;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;position: relative;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-label-container {position: relative;z-index: 2;text-align: center;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97 div.sk-text-repr-fallback {display: none;}</style><div id='sk-c9c00a3f-ef15-4e0b-904e-952e32e38f97' class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ForecastingPipeline(steps=[(&#x27;log_column_transformer&#x27;,\n",
       "                            ColumnwiseTransformer(columns=[&#x27;rolling_mean&#x27;,\n",
       "                                                           &#x27;wind_reserve_margin&#x27;,\n",
       "                                                           &#x27;hydro_reserve_margin&#x27;,\n",
       "                                                           &#x27;northwest_load&#x27;,\n",
       "                                                           &#x27;gas_supply_mix&#x27;,\n",
       "                                                           &#x27;hydro_tng&#x27;,\n",
       "                                                           &#x27;rolling_median&#x27;,\n",
       "                                                           &#x27;rolling_max&#x27;,\n",
       "                                                           &#x27;system_load&#x27;,\n",
       "                                                           &#x27;gas_tng&#x27;,\n",
       "                                                           &#x27;calgary_load&#x27;,\n",
       "                                                           &#x27;exp_moving_avg&#x27;,\n",
       "                                                           &#x27;total_reserve_margin&#x27;,\n",
       "                                                           &#x27;demand_supply_ratio&#x27;,\n",
       "                                                           &#x27;fossil_fuel_ratio&#x27;],\n",
       "                                                  transfo...\n",
       "                            TransformedTargetForecaster(steps=[(&#x27;log_column_transformer&#x27;,\n",
       "                                                                LogTransformer()),\n",
       "                                                               (&#x27;std_column_transformer&#x27;,\n",
       "                                                                TabularToSeriesAdaptor(transformer=StandardScaler())),\n",
       "                                                               (&#x27;forecast&#x27;,\n",
       "                                                                DirectTabularRegressionForecaster(estimator=ElasticNetCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             n_jobs=-1, random_state=42),\n",
       "                                                                                                  window_length=24))]))])</pre><b>Please rerun this cell to show the HTML repr or trust the notebook.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class='sk-label-container'><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('8a134fb6-1ba9-4813-bb29-8d81edb6e3a9') type=\"checkbox\" ><label for=UUID('8a134fb6-1ba9-4813-bb29-8d81edb6e3a9') class='sk-toggleable__label sk-toggleable__label-arrow'>ForecastingPipeline</label><div class=\"sk-toggleable__content\"><pre>ForecastingPipeline(steps=[(&#x27;log_column_transformer&#x27;,\n",
       "                            ColumnwiseTransformer(columns=[&#x27;rolling_mean&#x27;,\n",
       "                                                           &#x27;wind_reserve_margin&#x27;,\n",
       "                                                           &#x27;hydro_reserve_margin&#x27;,\n",
       "                                                           &#x27;northwest_load&#x27;,\n",
       "                                                           &#x27;gas_supply_mix&#x27;,\n",
       "                                                           &#x27;hydro_tng&#x27;,\n",
       "                                                           &#x27;rolling_median&#x27;,\n",
       "                                                           &#x27;rolling_max&#x27;,\n",
       "                                                           &#x27;system_load&#x27;,\n",
       "                                                           &#x27;gas_tng&#x27;,\n",
       "                                                           &#x27;calgary_load&#x27;,\n",
       "                                                           &#x27;exp_moving_avg&#x27;,\n",
       "                                                           &#x27;total_reserve_margin&#x27;,\n",
       "                                                           &#x27;demand_supply_ratio&#x27;,\n",
       "                                                           &#x27;fossil_fuel_ratio&#x27;],\n",
       "                                                  transfo...\n",
       "                            TransformedTargetForecaster(steps=[(&#x27;log_column_transformer&#x27;,\n",
       "                                                                LogTransformer()),\n",
       "                                                               (&#x27;std_column_transformer&#x27;,\n",
       "                                                                TabularToSeriesAdaptor(transformer=StandardScaler())),\n",
       "                                                               (&#x27;forecast&#x27;,\n",
       "                                                                DirectTabularRegressionForecaster(estimator=ElasticNetCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             n_jobs=-1, random_state=42),\n",
       "                                                                                                  window_length=24))]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('a4687ee6-15c3-49ad-96d2-93ec080fb159') type=\"checkbox\" ><label for=UUID('a4687ee6-15c3-49ad-96d2-93ec080fb159') class='sk-toggleable__label sk-toggleable__label-arrow'>LogTransformer</label><div class=\"sk-toggleable__content\"><pre>LogTransformer()</pre></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('e69b5eba-ba69-48e1-b303-bde26f96e66c') type=\"checkbox\" ><label for=UUID('e69b5eba-ba69-48e1-b303-bde26f96e66c') class='sk-toggleable__label sk-toggleable__label-arrow'>StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('3cc29bfd-39a5-4a21-8f53-86f1fdcd39a0') type=\"checkbox\" ><label for=UUID('3cc29bfd-39a5-4a21-8f53-86f1fdcd39a0') class='sk-toggleable__label sk-toggleable__label-arrow'>LogTransformer</label><div class=\"sk-toggleable__content\"><pre>LogTransformer()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('50f9bc41-c948-4610-93bc-f0edd868c901') type=\"checkbox\" ><label for=UUID('50f9bc41-c948-4610-93bc-f0edd868c901') class='sk-toggleable__label sk-toggleable__label-arrow'>StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class='sk-item'><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=UUID('b3c9f83a-a0fd-4319-ac38-2da793f091b0') type=\"checkbox\" ><label for=UUID('b3c9f83a-a0fd-4319-ac38-2da793f091b0') class='sk-toggleable__label sk-toggleable__label-arrow'>ElasticNetCV</label><div class=\"sk-toggleable__content\"><pre>ElasticNetCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             n_jobs=-1, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ForecastingPipeline(steps=[('log_column_transformer',\n",
       "                            ColumnwiseTransformer(columns=['rolling_mean',\n",
       "                                                           'wind_reserve_margin',\n",
       "                                                           'hydro_reserve_margin',\n",
       "                                                           'northwest_load',\n",
       "                                                           'gas_supply_mix',\n",
       "                                                           'hydro_tng',\n",
       "                                                           'rolling_median',\n",
       "                                                           'rolling_max',\n",
       "                                                           'system_load',\n",
       "                                                           'gas_tng',\n",
       "                                                           'calgary_load',\n",
       "                                                           'exp_moving_avg',\n",
       "                                                           'total_reserve_margin',\n",
       "                                                           'demand_supply_ratio',\n",
       "                                                           'fossil_fuel_ratio'],\n",
       "                                                  transfo...\n",
       "                            TransformedTargetForecaster(steps=[('log_column_transformer',\n",
       "                                                                LogTransformer()),\n",
       "                                                               ('std_column_transformer',\n",
       "                                                                TabularToSeriesAdaptor(transformer=StandardScaler())),\n",
       "                                                               ('forecast',\n",
       "                                                                DirectTabularRegressionForecaster(estimator=ElasticNetCV(cv=TimeSeriesSplit(gap=0, max_train_size=None, n_splits=5, test_size=None),\n",
       "             n_jobs=-1, random_state=42),\n",
       "                                                                                                  window_length=24))]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgbm_pipeline.fit(y=y_train, X=X_train, fh=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lgbm_pipeline.predict(fh, X=X_train.tail(1))\n",
    "y_pred.columns = [f\"cutoff_hour_{lgbm_pipeline.cutoff.hour[0]}\"]\n",
    "rolling_prediction_df = pd.concat([rolling_prediction_df, y_pred], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cutoff_hour_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-02-01 00:00:00</th>\n",
       "      <td>70.822313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01 01:00:00</th>\n",
       "      <td>67.435105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01 02:00:00</th>\n",
       "      <td>66.408004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01 03:00:00</th>\n",
       "      <td>68.838509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-02-01 04:00:00</th>\n",
       "      <td>74.339863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 19:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 20:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 21:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 22:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-03-31 23:00:00</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1416 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     cutoff_hour_23\n",
       "2023-02-01 00:00:00       70.822313\n",
       "2023-02-01 01:00:00       67.435105\n",
       "2023-02-01 02:00:00       66.408004\n",
       "2023-02-01 03:00:00       68.838509\n",
       "2023-02-01 04:00:00       74.339863\n",
       "...                             ...\n",
       "2023-03-31 19:00:00             NaN\n",
       "2023-03-31 20:00:00             NaN\n",
       "2023-03-31 21:00:00             NaN\n",
       "2023-03-31 22:00:00             NaN\n",
       "2023-03-31 23:00:00             NaN\n",
       "\n",
       "[1416 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolling_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updating with actual values at 2023-02-01 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-01-31 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-01 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-01 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-01 00:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-01 12:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-01 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-01 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-02 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-01 12:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-02 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-01 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-02 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-03 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-02 00:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-02 12:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-02 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-02 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-04 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-02 12:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-03 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-02 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-03 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-05 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-03 00:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-03 12:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-03 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-03 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-06 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-03 12:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-04 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-03 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-04 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-07 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-04 00:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-04 12:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-04 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-04 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-08 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-04 12:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-05 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-04 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-05 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-09 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-05 00:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-05 12:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-05 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-05 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-10 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-05 12:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-06 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-05 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-06 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-11 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-06 00:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-06 12:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-06 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-06 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-12 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-06 12:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-07 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-06 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-07 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-13 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-07 00:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-07 12:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-07 11:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Cut off after update: DatetimeIndex(['2023-02-07 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n",
      "Predicting for DatetimeIndex(['2023-02-14 11:00:00'], dtype='datetime64[ns]', name='date', freq=None)\n",
      "Update and prediction done for 2023-02-07 12:00:00\n",
      "----------------------------------------------------------------------------------\n",
      "Updating with actual values at 2023-02-08 00:00:00\n",
      "Cut off before update: DatetimeIndex(['2023-02-07 23:00:00'], dtype='datetime64[ns]', name='date', freq='H')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mUpdating with actual values at \u001b[39m\u001b[39m{\u001b[39;00mnew_observation_y\u001b[39m.\u001b[39mindex[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCut off before update: \u001b[39m\u001b[39m{\u001b[39;00mlgbm_pipeline\u001b[39m.\u001b[39mcutoff\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 13\u001b[0m lgbm_pipeline\u001b[39m.\u001b[39;49mupdate(y\u001b[39m=\u001b[39;49mnew_observation_y, X\u001b[39m=\u001b[39;49mnew_observation_X, update_params\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mCut off after update: \u001b[39m\u001b[39m{\u001b[39;00mlgbm_pipeline\u001b[39m.\u001b[39mcutoff\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     17\u001b[0m lgbm_pipeline\u001b[39m.\u001b[39mcutoff\u001b[39m.\u001b[39mfreq \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mH\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:884\u001b[0m, in \u001b[0;36mBaseForecaster.update\u001b[1;34m(self, y, X, update_params)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39m# checks and conversions complete, pass to inner fit\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_vectorized:\n\u001b[1;32m--> 884\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(y\u001b[39m=\u001b[39;49my_inner, X\u001b[39m=\u001b[39;49mX_inner, update_params\u001b[39m=\u001b[39;49mupdate_params)\n\u001b[0;32m    885\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize(\u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m=\u001b[39my_inner, X\u001b[39m=\u001b[39mX_inner, update_params\u001b[39m=\u001b[39mupdate_params)\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\compose\\_pipeline.py:675\u001b[0m, in \u001b[0;36mForecastingPipeline._update\u001b[1;34m(self, y, X, update_params)\u001b[0m\n\u001b[0;32m    672\u001b[0m             X \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39mtransform(X\u001b[39m=\u001b[39mX, y\u001b[39m=\u001b[39my)\n\u001b[0;32m    674\u001b[0m _, forecaster \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps_[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 675\u001b[0m forecaster\u001b[39m.\u001b[39;49mupdate(y\u001b[39m=\u001b[39;49my, X\u001b[39m=\u001b[39;49mX, update_params\u001b[39m=\u001b[39;49mupdate_params)\n\u001b[0;32m    676\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:884\u001b[0m, in \u001b[0;36mBaseForecaster.update\u001b[1;34m(self, y, X, update_params)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39m# checks and conversions complete, pass to inner fit\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_vectorized:\n\u001b[1;32m--> 884\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(y\u001b[39m=\u001b[39;49my_inner, X\u001b[39m=\u001b[39;49mX_inner, update_params\u001b[39m=\u001b[39;49mupdate_params)\n\u001b[0;32m    885\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize(\u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m=\u001b[39my_inner, X\u001b[39m=\u001b[39mX_inner, update_params\u001b[39m=\u001b[39mupdate_params)\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\compose\\_pipeline.py:1031\u001b[0m, in \u001b[0;36mTransformedTargetForecaster._update\u001b[1;34m(self, y, X, update_params)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         t\u001b[39m.\u001b[39mupdate(X\u001b[39m=\u001b[39my, y\u001b[39m=\u001b[39mX, update_params\u001b[39m=\u001b[39mupdate_params)\n\u001b[0;32m   1029\u001b[0m         y \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39mtransform(X\u001b[39m=\u001b[39my, y\u001b[39m=\u001b[39mX)\n\u001b[1;32m-> 1031\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforecaster_\u001b[39m.\u001b[39;49mupdate(y\u001b[39m=\u001b[39;49my, X\u001b[39m=\u001b[39;49mX, update_params\u001b[39m=\u001b[39;49mupdate_params)\n\u001b[0;32m   1033\u001b[0m \u001b[39m# transform post\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m \u001b[39mfor\u001b[39;00m _, t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransformers_post_:\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:884\u001b[0m, in \u001b[0;36mBaseForecaster.update\u001b[1;34m(self, y, X, update_params)\u001b[0m\n\u001b[0;32m    882\u001b[0m \u001b[39m# checks and conversions complete, pass to inner fit\u001b[39;00m\n\u001b[0;32m    883\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_vectorized:\n\u001b[1;32m--> 884\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_update(y\u001b[39m=\u001b[39;49my_inner, X\u001b[39m=\u001b[39;49mX_inner, update_params\u001b[39m=\u001b[39;49mupdate_params)\n\u001b[0;32m    885\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    886\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize(\u001b[39m\"\u001b[39m\u001b[39mupdate\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m=\u001b[39my_inner, X\u001b[39m=\u001b[39mX_inner, update_params\u001b[39m=\u001b[39mupdate_params)\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:1920\u001b[0m, in \u001b[0;36mBaseForecaster._update\u001b[1;34m(self, y, X, update_params)\u001b[0m\n\u001b[0;32m   1918\u001b[0m _converter_store_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_converter_store_y\n\u001b[0;32m   1919\u001b[0m \u001b[39m# refit with updated data, not only passed data\u001b[39;00m\n\u001b[1;32m-> 1920\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(y\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_y, X\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_X, fh\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fh)\n\u001b[0;32m   1921\u001b[0m \u001b[39m# todo: should probably be self._fit, not self.fit\u001b[39;00m\n\u001b[0;32m   1922\u001b[0m \u001b[39m# but looping to self.fit for now to avoid interface break\u001b[39;00m\n\u001b[0;32m   1923\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_y_mtype_last_seen \u001b[39m=\u001b[39m mtype_last_seen\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\base\\_base.py:352\u001b[0m, in \u001b[0;36mBaseForecaster.fit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[39m# we call the ordinary _fit if no looping/vectorization needed\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m vectorization_needed:\n\u001b[1;32m--> 352\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(y\u001b[39m=\u001b[39;49my_inner, X\u001b[39m=\u001b[39;49mX_inner, fh\u001b[39m=\u001b[39;49mfh)\n\u001b[0;32m    353\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    354\u001b[0m     \u001b[39m# otherwise we call the vectorized version of fit\u001b[39;00m\n\u001b[0;32m    355\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vectorize(\u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m, y\u001b[39m=\u001b[39my_inner, X\u001b[39m=\u001b[39mX_inner, fh\u001b[39m=\u001b[39mfh)\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sktime\\forecasting\\compose\\_reduce.py:527\u001b[0m, in \u001b[0;36m_DirectReducer._fit\u001b[1;34m(self, y, X, fh)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindows_identical \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 527\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(Xt, yt[:, i])\n\u001b[0;32m    528\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m         \u001b[39mif\u001b[39;00m (fh_rel[i] \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1712\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1707\u001b[0m     model\u001b[39m.\u001b[39mprecompute \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m   1709\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1710\u001b[0m     \u001b[39m# MultiTaskElasticNetCV does not (yet) support sample_weight, even\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m     \u001b[39m# not sample_weight=None.\u001b[39;00m\n\u001b[1;32m-> 1712\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X, y)\n\u001b[0;32m   1713\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1714\u001b[0m     model\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1004\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m   1002\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1003\u001b[0m     this_Xy \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1004\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpath(\n\u001b[0;32m   1005\u001b[0m     X,\n\u001b[0;32m   1006\u001b[0m     y[:, k],\n\u001b[0;32m   1007\u001b[0m     l1_ratio\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49ml1_ratio,\n\u001b[0;32m   1008\u001b[0m     eps\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1009\u001b[0m     n_alphas\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1010\u001b[0m     alphas\u001b[39m=\u001b[39;49m[alpha],\n\u001b[0;32m   1011\u001b[0m     precompute\u001b[39m=\u001b[39;49mprecompute,\n\u001b[0;32m   1012\u001b[0m     Xy\u001b[39m=\u001b[39;49mthis_Xy,\n\u001b[0;32m   1013\u001b[0m     copy_X\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1014\u001b[0m     coef_init\u001b[39m=\u001b[39;49mcoef_[k],\n\u001b[0;32m   1015\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1016\u001b[0m     return_n_iter\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1017\u001b[0m     positive\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpositive,\n\u001b[0;32m   1018\u001b[0m     check_input\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1019\u001b[0m     \u001b[39m# from here on **params\u001b[39;49;00m\n\u001b[0;32m   1020\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[0;32m   1021\u001b[0m     X_offset\u001b[39m=\u001b[39;49mX_offset,\n\u001b[0;32m   1022\u001b[0m     X_scale\u001b[39m=\u001b[39;49mX_scale,\n\u001b[0;32m   1023\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[0;32m   1024\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrandom_state,\n\u001b[0;32m   1025\u001b[0m     selection\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselection,\n\u001b[0;32m   1026\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1027\u001b[0m )\n\u001b[0;32m   1028\u001b[0m coef_[k] \u001b[39m=\u001b[39m this_coef[:, \u001b[39m0\u001b[39m]\n\u001b[0;32m   1029\u001b[0m dual_gaps_[k] \u001b[39m=\u001b[39m this_dual_gap[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\rkris\\miniconda3\\envs\\slalomenv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:631\u001b[0m, in \u001b[0;36menet_path\u001b[1;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[0;32m    617\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39menet_coordinate_descent_gram(\n\u001b[0;32m    618\u001b[0m         coef_,\n\u001b[0;32m    619\u001b[0m         l1_reg,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    628\u001b[0m         positive,\n\u001b[0;32m    629\u001b[0m     )\n\u001b[0;32m    630\u001b[0m \u001b[39melif\u001b[39;00m precompute \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m--> 631\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39;49menet_coordinate_descent(\n\u001b[0;32m    632\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[0;32m    633\u001b[0m     )\n\u001b[0;32m    634\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    635\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    636\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPrecompute should be one of True, False, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or array-like. Got \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    637\u001b[0m         \u001b[39m%\u001b[39m precompute\n\u001b[0;32m    638\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# emulating the rolling prediction for the next hours\n",
    "\n",
    "for i in range(0, len(y_test_full), 12):\n",
    "\n",
    "        new_observation_y, new_observation_X  = y_test_full[i:i+12], X_test[i:i+12]\n",
    "        \n",
    "        new_observation_y = new_observation_y.asfreq('H')\n",
    "        new_observation_X = new_observation_X.asfreq('H')\n",
    "\n",
    "        print(f'Updating with actual values at {new_observation_y.index[0]}')\n",
    "        print(f'Cut off before update: {lgbm_pipeline.cutoff}')\n",
    "\n",
    "        lgbm_pipeline.update(y=new_observation_y, X=new_observation_X, update_params=True)\n",
    "\n",
    "        print(f'Cut off after update: {lgbm_pipeline.cutoff}')\n",
    "\n",
    "        lgbm_pipeline.cutoff.freq = 'H'\n",
    "\n",
    "        cutoff_time = lgbm_pipeline.cutoff\n",
    "        prediction_for = cutoff_time + pd.DateOffset(hours=i)\n",
    "\n",
    "        print(f'Predicting for {prediction_for}')\n",
    "        \n",
    "        y_pred = lgbm_pipeline.predict(fh, X=new_observation_X)\n",
    "        \n",
    "        y_pred.columns = [f\"cutoff_hour_{lgbm_pipeline.cutoff.hour[0]}\"]\n",
    "        \n",
    "        rolling_prediction_df = pd.concat([rolling_prediction_df, y_pred], axis=1)\n",
    "        \n",
    "        print(f'Update and prediction done for {new_observation_y.index[0]}')\n",
    "        print(f'----------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_list = []\n",
    "fold_actuals = []\n",
    "fold_predictions_list = []\n",
    "fold_predictions_low_list = []\n",
    "fold_predictions_high_list = []\n",
    "\n",
    "for col in range(rolling_prediction_df.shape[1]-1):\n",
    "    \n",
    "    fold_predictions = rolling_prediction_df.iloc[:, col].dropna()\n",
    "    \n",
    "    fold_indices = fold_predictions.index  \n",
    "\n",
    "    y_test_subset = y_test_full.loc[fold_indices]  \n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y_test_subset, fold_predictions))  \n",
    "    \n",
    "    rmse_list.append(rmse)\n",
    "\n",
    "    fold_actuals.append(y_test_subset)\n",
    "    fold_predictions_list.append(fold_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Average RMSE of all folds\n",
    "print(f\"Average RMSE for each fold: {np.mean(rmse_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print max RMSE\n",
    "print(f\"Max RMSE for each fold: {np.max(rmse_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print hightst 5 RMSE\n",
    "print(f\"Top 5 RMSE for each fold: {np.sort(rmse_list)[-5:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hist = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/slalom-ubc-mds/Power-Price-Prediction/main/data/processed/filtered_target_medium.csv\",\n",
    "    parse_dates=[\"date\"],\n",
    "    index_col=\"date\",\n",
    ")\n",
    "\n",
    "y_hist = y_hist.sort_values(by=\"date\")\n",
    "y_hist = y_hist.asfreq(\"H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Date','Data', 'RMSE'])\n",
    "\n",
    "ddf = pd.DataFrame(columns=['HistoricalPrice',\t'FuturePrice',\t'Predicted', 'timestep'])\n",
    "\n",
    "for i in range(len(fold_actuals)):\n",
    "\n",
    "    df = y_hist[y_hist.index < fold_predictions_list[i].index[0]]\n",
    "\n",
    "    df = df.iloc[-24:,:]\n",
    "    \n",
    "    predictions = np.array(fold_predictions_list[i])\n",
    "    \n",
    "    date_index = fold_actuals[i].index\n",
    "    \n",
    "    hist = pd.DataFrame(df.iloc[-12:,:]['price']).rename(columns={'price':'HistoricalPrice'})\n",
    "    \n",
    "    fitu = pd.DataFrame(fold_actuals[i]).rename(columns={'price':'FuturePrice'})\n",
    "    \n",
    "    pred = pd.DataFrame(predictions, index=date_index).rename(columns={0:'Predicted'})\n",
    "\n",
    "    histfitu = pd.merge(hist, fitu, how='outer', left_index=True, right_index=True)\n",
    "    \n",
    "    hfp = pd.merge(histfitu, pred, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "    hfp['timestep'] = i\n",
    "    \n",
    "    hfp['periodstep'] = range(1, len(hfp)+1)\n",
    "    \n",
    "    hfp = hfp.reset_index()\n",
    "    \n",
    "    results_df = results_df.append({'Date':df.index[-1],\n",
    "                                    'Data' : hfp\n",
    "                                    }, ignore_index=True)\n",
    "                                    \n",
    "    ddf = pd.concat([ddf,hfp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fold_actuals), len(fold_predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.line(ddf, x=\"periodstep\", y=[\"HistoricalPrice\", \"FuturePrice\", \"Predicted\"], animation_frame=\"timestep\")\n",
    "# fig.update_layout(height=700)  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def get_aeso_predictions(start_date, end_date):\n",
    "    url = \"https://api.aeso.ca/report/v1.1/price/poolPrice\"\n",
    "    headers = {\n",
    "        \"accept\": \"application/json\",\n",
    "        \"X-API-Key\": \"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ6MHo4MnIiLCJpYXQiOjE2ODM1NzQyMTh9.Gbod9kjeDwP4SOJibSFof63X7GGZxbZdBmBVrgE409w\",\n",
    "    }\n",
    "    params = {\n",
    "        \"startDate\": start_date.date().strftime(\"%Y-%m-%d\"),\n",
    "        \"endDate\": end_date.date().strftime(\"%Y-%m-%d\"),\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "    data = response.json()[\"return\"][\"Pool Price Report\"]\n",
    "    df = pd.DataFrame(data)\n",
    "    df[\"actual\"] = pd.to_numeric(df[\"pool_price\"])\n",
    "    df[\"forecast\"] = pd.to_numeric(df[\"forecast_pool_price\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aeso_predictions_df = get_aeso_predictions(y_test_full.index[0], y_test_full.index[-1])\n",
    "rmse_aeso_predictions = mean_squared_error(aeso_predictions_df['actual'], aeso_predictions_df['forecast'], squared=False)\n",
    "print(f\"RMSE for the predictions by AESO for the same time period as the test set: {round(rmse_aeso_predictions, 2)} CAD/MWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "slalomenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
